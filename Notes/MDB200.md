# MDB200 - MongoDB Advanced Topics

## Table of Contents
1. [Indexes and Optimization Part 1](#indexes-and-optimization-part-1)
2. [Indexes and Optimization Part 2](#indexes-and-optimization-part-2)
3. [Finding Slow Operations with Logs and Metrics](#finding-slow-operations-with-logs-and-metrics)
4. [Intro to Atlas Search and Atlas Vector Search](#intro-to-atlas-search-and-atlas-vector-search)

## Indexes and Optimization Part 1

### Index Fundamentals Review

#### What Are Indexes?
Indexes are special data structures that store a small portion of the collection's data in an easy-to-traverse form. They improve the speed of data retrieval operations but add overhead to data insertion, update, and deletion.

#### B-tree Structure
MongoDB indexes use a B-tree data structure to store the index keys:
- Balanced tree structure
- Allows for efficient range queries
- Self-balancing (maintains consistent performance regardless of data size)

#### Index Types
1. **Single Field Index**
   ```javascript
   db.collection.createIndex({ field: 1 }) // 1 for ascending, -1 for descending
   ```

2. **Compound Index**
   ```javascript
   db.collection.createIndex({ field1: 1, field2: -1 })
   ```

3. **Multikey Index** (for array fields)
   ```javascript
   db.collection.createIndex({ "tags": 1 }) // Where tags is an array field
   ```

4. **Text Index** (for text search)
   ```javascript
   db.collection.createIndex({ content: "text" })
   ```

5. **Geospatial Index**
   ```javascript
   db.collection.createIndex({ location: "2dsphere" })
   ```

6. **Hashed Index** (for sharding)
   ```javascript
   db.collection.createIndex({ _id: "hashed" })
   ```

### Index Statistics and Analysis

#### Viewing Existing Indexes
```javascript
// List all indexes in a collection
db.collection.getIndexes()

// View index sizes
db.collection.stats().indexSizes
```

#### Index Usage Statistics
```javascript
// Check which indexes are being used
db.collection.aggregate([
  { $indexStats: {} }
])
```

### Query Optimization

#### Explain Plan
The `explain()` method is used to view the execution plan for a query:

```javascript
// Explain a query
db.collection.find({ age: { $gt: 25 } }).explain()

// Get more detailed information (executionStats or allPlansExecution)
db.collection.find({ age: { $gt: 25 } }).explain("executionStats")
```

#### Explain Output Stages:
- **COLLSCAN**: Collection scan (no index used) - inefficient for large collections
- **IXSCAN**: Index scan - using an index
- **FETCH**: Document retrieval after identifying documents
- **SORT**: In-memory sort - can be memory-intensive if not using an index
- **PROJECTION**: Field filtering

### Covered Queries
A covered query is satisfied entirely using an index, without examining documents:

```javascript
// Covered query example (if there's an index on age and name)
db.collection.find(
  { age: { $gt: 25 } },    // Query
  { name: 1, age: 1, _id: 0 }  // Projection (only fields in the index)
)
```

## Indexes and Optimization Part 2

### Index Performance Considerations

#### Index Selectivity
High selectivity (returning fewer documents) makes an index more effective:
- **High selectivity**: Field values that are more unique
- **Low selectivity**: Field values that are highly repeated

#### When to Use Compound Indexes
Consider compound indexes when:
- Queries frequently filter on multiple fields
- You need to support sorting on multiple fields
- You want to cover a query with an index

#### Compound Index Field Order
The order of fields in a compound index is critical:
1. **Equality fields first**: Fields queried with equality (`field: value`)
2. **Sort fields next**: Fields used in sort operations
3. **Range fields last**: Fields queried with range conditions (`$gt`, `$lt`, etc.)

```javascript
// For queries like: 
// db.collection.find({ status: "active", category: "electronics" }).sort({ date: -1 })
// Create index:
db.collection.createIndex({ status: 1, category: 1, date: -1 })
```

### Index Limitations and Overhead

#### Storage Impact
- Each index requires additional disk space
- Write operations become slower as indexes increase

#### Memory Usage
- Working set (frequently accessed data and indexes) should fit in RAM
- When indexes don't fit in RAM, performance degrades significantly

#### Index Cardinality
For a collection with n documents:
- Single field index: Up to n entries
- Compound index: Up to n entries
- Multikey index: Can have more than n entries (one per array element)

### MongoDB Performance Monitoring

#### System Resource Metrics
- **CPU Usage**: High CPU can indicate inefficient queries or inadequate indexing
- **Memory Usage**: Monitor working set size vs. available RAM
- **Disk I/O**: High I/O can indicate indexes don't fit in memory

#### MongoDB Server Status
```javascript
db.serverStatus()
```

Key metrics to monitor:
- **connections**: Number of current connections
- **globalLock**: Indicates contention for resources
- **opcounters**: Operation counters (queries, inserts, updates, deletes)
- **wiredTiger**: Storage engine metrics

### Performance Best Practices

#### Indexing Best Practices
1. Create indexes to support common queries
2. Avoid creating unnecessary indexes
3. Consider dropping unused indexes
4. Use compound indexes effectively
5. Be mindful of index size vs. collection size

#### Query Optimization
1. Use specific queries to leverage indexes
2. Limit results when possible
3. Use projections to return only needed fields
4. Avoid negation operators that can't use indexes efficiently
5. Use covered queries when possible

## Finding Slow Operations with Logs and Metrics

### Performance Metrics

#### Key MongoDB Metrics to Monitor

##### System Metrics
- **CPU Utilization**: Should generally be below 70% for headroom
- **Memory Usage**: Working set should fit in RAM
- **Swappiness**: Set to 1 or 0 to minimize swapping (critical for performance)
- **Disk I/O**: Monitor for latency and throughput bottlenecks

##### MongoDB Operation Counters
- **Queries, Updates, Inserts, Deletes**: Track operation rates
- **TTL Deletions**: Can consume significant resources if many documents expire simultaneously

##### Cache Metrics
- **Cache Hit Ratio**: Should be around 80% for healthy systems
  - Lower ratios indicate working set doesn't fit in RAM
  - When dirty cache ratio drops below 20%, eviction pressure increases

##### Replication Metrics
- **Replication Lag**: Time delay between operations on primary and secondary nodes
- **Flow Control**: Activated when secondaries fall behind (throttles writes on primary)

#### Identifying Performance Issues
Common patterns to watch for:
1. **Sudden Spikes**: In CPU, memory, or operation counters
2. **Growing Replication Lag**: Secondaries falling behind
3. **Decreasing Cache Hit Ratio**: Working set growing beyond RAM
4. **Increasing Response Times**: For typical operations

### Profiling and Logging

#### Database Profiler
MongoDB's profiler collects detailed information about operations:

```javascript
// Enable profiling for slow operations (>100ms)
db.setProfilingLevel(1, { slowms: 100 })

// Enable profiling for all operations (high overhead)
db.setProfilingLevel(2)

// View profiling data
db.system.profile.find().sort({ ts: -1 }).limit(10)
```

#### Profiling Level Options
- **Level 0**: No profiling (default)
- **Level 1**: Profile slow operations only (recommended)
- **Level 2**: Profile all operations (high overhead, use sparingly)

#### Log Analysis
MongoDB logs provide valuable information:

```
// Example slow query log entry
2023-03-01T12:34:56.789+00:00 I COMMAND [conn123] command database.collection appName: "MongoDB Shell" command: find { find: "collection", filter: { status: "active" }, sort: { timestamp: -1 } } planSummary: COLLSCAN keysExamined:0 docsExamined:10000 cursorExhausted:1 numYields:78 queryHash:ABCDEF123456 planCacheKey:7890ABCDEF12 reslen:20 locks:{ ... } protocol:op_msg 300ms
```

Key parts to analyze:
- **planSummary**: COLLSCAN indicates no index was used
- **docsExamined**: Number of documents scanned
- **keysExamined**: Number of index entries scanned
- **numYields**: How often the operation yielded to other operations
- **locks**: Lock information
- **300ms**: Execution time

### Database Monitoring Tools

#### MongoDB Atlas Monitoring
Provides built-in monitoring dashboards for:
- Query performance
- Database metrics
- Hardware utilization
- Real-time alerts

#### MongoDB Compass
GUI tool for performance analysis:
- Query optimization
- Index suggestions
- Real-time server statistics
- Schema visualization

#### mongotop and mongostat
Command-line tools for monitoring:

```bash
# Monitor read/write activity by collection
mongotop --host mongodb://localhost:27017 5

# Monitor MongoDB server statistics
mongostat --host mongodb://localhost:27017 5
```

### Diagnosing and Resolving Slow Operations

#### Common Performance Issues and Solutions

1. **Missing Indexes**
   - Symptom: COLLSCAN in explain plans, high document examination counts
   - Solution: Create appropriate indexes

2. **Inefficient Queries**
   - Symptom: Complex queries with high execution times
   - Solution: Rewrite queries to better use indexes

3. **Working Set Larger than RAM**
   - Symptom: Low cache hit ratio, high page fault rate
   - Solution: Increase RAM or shard data across multiple servers

4. **Long-Running Operations Blocking Others**
   - Symptom: Increasing operation queues, lock contention
   - Solution: Identify and terminate or optimize long-running operations

#### Killing Slow Operations
When necessary, you can terminate problematic operations:

```javascript
// Find currently running operations
db.currentOp()

// Kill a specific operation
db.killOp(opId)
```

## Intro to Atlas Search and Atlas Vector Search

### Atlas Search

#### What is Atlas Search?
Atlas Search is a full-text search solution built on top of Apache Lucene, integrated directly with MongoDB Atlas. It enables advanced text search capabilities without requiring separate search infrastructure.

#### Features
- **Text Search**: Beyond basic regex or wildcard matching
- **Relevance Ranking**: Results ordered by relevance
- **Language Support**: Analyzers for many languages
- **Facets**: For categorizing search results
- **Highlighting**: Mark matching text in results

#### Creating a Search Index
```javascript
// Atlas Search index definition
{
  "mappings": {
    "dynamic": true,
    "fields": {
      "description": {
        "type": "string",
        "analyzer": "lucene.english"
      },
      "title": {
        "type": "string",
        "analyzer": "lucene.english"
      },
      "tags": {
        "type": "string",
        "analyzer": "lucene.standard"
      }
    }
  }
}
```

#### Basic Search Queries
```javascript
// Simple text search
db.collection.aggregate([
  {
    $search: {
      "text": {
        "query": "mongodb atlas",
        "path": "description"
      }
    }
  },
  {
    $limit: 10
  }
])

// Fuzzy search with typo tolerance
db.collection.aggregate([
  {
    $search: {
      "text": {
        "query": "mongodeb",
        "path": "title",
        "fuzzy": {
          "maxEdits": 1
        }
      }
    }
  }
])
```

### Atlas Vector Search

#### What is Vector Search?
Vector search enables similarity search using vector embeddings - numerical representations that capture semantic meaning. It's ideal for applications like semantic search, image similarity, and recommendation engines.

#### Key Concepts
- **Embeddings**: Vectors representing the semantic meaning of data
- **Vector Indexes**: Special indexes optimized for vector similarity operations
- **Similarity Measurements**: Cosine similarity, Euclidean distance, etc.
- **K-Nearest Neighbors (KNN)**: Find the most similar items to a query vector

#### Creating a Vector Search Index
```javascript
// Vector search index definition
{
  "fields": [
    {
      "type": "vector",
      "path": "embedding",
      "numDimensions": 768,
      "similarity": "cosine"
    }
  ]
}
```

#### Vector Search Queries
```javascript
// Basic KNN vector search
db.collection.aggregate([
  {
    $vectorSearch: {
      "index": "vector_index",
      "path": "embedding",
      "queryVector": [0.1, 0.2, ..., 0.7],
      "numCandidates": 100,
      "limit": 10
    }
  }
])

// Hybrid search (combining text and vector search)
db.collection.aggregate([
  {
    $search: {
      "compound": {
        "must": [
          {
            "text": {
              "query": "database",
              "path": "description"
            }
          }
        ],
        "should": [
          {
            "knnBeta": {
              "vector": [0.1, 0.2, ..., 0.7],
              "path": "embedding",
              "k": 10
            }
          }
        ]
      }
    }
  }
])
```

### RAG (Retrieval-Augmented Generation) with Vector Search

#### What is RAG?
RAG combines retrieval systems with generative AI to produce more accurate, contextual, and relevant responses by retrieving and incorporating relevant information from a knowledge base.

#### RAG Architecture with MongoDB
1. **Document Processing**: Convert documents to vector embeddings
2. **Storage**: Store documents and embeddings in MongoDB
3. **Retrieval**: Use vector search to find relevant documents
4. **Generation**: Send retrieved context to LLMs for response generation

#### Example RAG Implementation
```javascript
// Store document with embedding
db.collection.insertOne({
  "title": "Introduction to MongoDB",
  "content": "MongoDB is a document database...",
  "embedding": [0.1, 0.2, ..., 0.7] // Vector from an embedding model
})

// Retrieve relevant documents for a query
db.collection.aggregate([
  {
    $vectorSearch: {
      "index": "content_embedding",
      "path": "embedding",
      "queryVector": queryEmbedding, // From embedding model
      "limit": 5
    }
  },
  {
    $project: {
      "title": 1,
      "content": 1,
      "_id": 0
    }
  }
])
```

### Dedicated Search Nodes

#### What are Dedicated Search Nodes?
Dedicated search nodes in Atlas are specialized instances that handle search and vector search workloads, isolating them from your primary database workload.

#### Benefits
- **Performance Isolation**: Search operations don't compete with regular database operations
- **Scaling**: Scale search capacity independently from database capacity
- **Cost Efficiency**: Optimize hardware for different workloads

#### Setting Up Dedicated Search Nodes
- Requires a minimum of 2 search nodes per region for high availability
- Can be managed through the Atlas UI
- No additional cost for Atlas Search itself, only for the dedicated nodes

#### Best Practices
1. Use dedicated search nodes for high-volume search workloads
2. Size search nodes based on index size and query volume
3. Monitor search node metrics separately from database metrics
4. Consider multi-region search nodes for global applications 